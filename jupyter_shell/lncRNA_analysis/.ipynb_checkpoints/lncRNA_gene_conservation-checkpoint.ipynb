{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "import shutil\n",
    "import glob\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from scipy import stats\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "%matplotlib inline\n",
    "%config InlineBackend.figure_format = 'svg'\n",
    "from multiprocessing import Pool\n",
    "from collections import Counter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Got 24 chromosomes from 24 bigWigs\n",
      "Processing\n"
     ]
    }
   ],
   "source": [
    "%%bash\n",
    "#获得所有wigFix的文件列表并存入数组\n",
    "cd \"/data/database/ucsc_phylo/placentalMammals\"\n",
    "wigFix_a=(`echo *.wigFix`)\n",
    "#写个循环批量实现\n",
    "for i in ${wigFix_a[@]}\n",
    "do\n",
    "  #用染色体名定义要输出的文件名。\n",
    "  wigFix_out=`echo $i|cut -d . -f 1|awk '{print $1\".bw\"}' -`\n",
    "  #将每个.wigFix文件转为.bw文件\n",
    "  wigToBigWig $i hg19.chrom.sizes $wigFix_out\n",
    "done\n",
    "#使用UCSC的bigWigMerge工具合并各个染色体的bw文件为.bedGraph文件，因为我没找到能合并为.bw的工具。。\n",
    "bigWigMerge chr10.bw  chr11.bw  chr12.bw chr13.bw  chr14.bw  chr15.bw chr16.bw  chr17.bw  chr18.bw chr19.bw  chr1.bw  chr20.bw chr21.bw  chr22.bw  chr2.bw chr3.bw  chr4.bw  chr5.bw chr6.bw  chr7.bw  chr8.bw chr9.bw  chrX.bw  chrY.bw phastCons46.bedGraph\n",
    "#将.bedgraph文件转为.bw文件。\n",
    "wigToBigWig  phastCons46.bedGraph  hg19.chrom.sizes  phastCons46.bw"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<multiprocessing.pool.ApplyResult at 0x7f543ffb2c18>"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "<multiprocessing.pool.ApplyResult at 0x7f543ff7a7f0>"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "<multiprocessing.pool.ApplyResult at 0x7f543ff88358>"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "<multiprocessing.pool.ApplyResult at 0x7f543ff89e10>"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "<multiprocessing.pool.ApplyResult at 0x7f543ff89a58>"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "<multiprocessing.pool.ApplyResult at 0x7f543ff89630>"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "<multiprocessing.pool.ApplyResult at 0x7f543ff89668>"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "<multiprocessing.pool.ApplyResult at 0x7f543ff89780>"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "<multiprocessing.pool.ApplyResult at 0x7f543ff894e0>"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "<multiprocessing.pool.ApplyResult at 0x7f543ff89518>"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "<multiprocessing.pool.ApplyResult at 0x7f543e73e0f0>"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "<multiprocessing.pool.ApplyResult at 0x7f543e73e160>"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "<multiprocessing.pool.ApplyResult at 0x7f543e73e240>"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "<multiprocessing.pool.ApplyResult at 0x7f543e73e2b0>"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "<multiprocessing.pool.ApplyResult at 0x7f543e73e390>"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "<multiprocessing.pool.ApplyResult at 0x7f543e73e400>"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "<multiprocessing.pool.ApplyResult at 0x7f543e73e4e0>"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "<multiprocessing.pool.ApplyResult at 0x7f543e73e588>"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "<multiprocessing.pool.ApplyResult at 0x7f543e73e5c0>"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "<multiprocessing.pool.ApplyResult at 0x7f543e73e6a0>"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "<multiprocessing.pool.ApplyResult at 0x7f543e73e780>"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "<multiprocessing.pool.ApplyResult at 0x7f543e73e828>"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "<multiprocessing.pool.ApplyResult at 0x7f543e73e898>"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "<multiprocessing.pool.ApplyResult at 0x7f543e73e860>"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "os.chdir(\"/data/database/ucsc_phylo/placentalMammals\")\n",
    "def wig_to_bed(wigFix):\n",
    "    os.system(\"less %s | wig2bed - > %s\" % (wigFix, wigFix.replace(\".wigFix\", \".bed\")))\n",
    "wigFix_list = glob.glob(\"*.wigFix\")\n",
    "# print(wigFix_list)\n",
    "pool = Pool(processes=8)\n",
    "for wigFix in wigFix_list:\n",
    "    pool.apply_async(wig_to_bed, (wigFix, ))\n",
    "#     wig_to_bed(wigFix)\n",
    "pool.close()\n",
    "pool.join()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%bash\n",
    "cd /data/database/ucsc_phylo/placentalMammals\n",
    "bedops --everything chr*.bed > placentalMammals.phyloP46.bed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "#less gencode.v28.annotation.gff3 | awk '$3==\"gene\"' - | gff2bed -| cut -f1-6 - > genes_v28.bed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%bash\n",
    "# Split the all-genes BED file into per-gene BED files, using cut, sort and uniq to acquire a listing of the names of each gene:\n",
    "$ mkdir perGene\n",
    "$ for name in `cut -f4 genes_v28.bed | sort | uniq`; do grep -F ${name} genes_v28.bed > perGene/${name}.bed; done"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "bash: line 2: /bin/ls: Argument list too long\n"
     ]
    }
   ],
   "source": [
    "%%bash\n",
    "cd /data/database/ucsc_phylo/placentalMammals\n",
    "for fn in `ls /data/database/hg19/perGene/*.bed`;do\n",
    "bedtools map -split -sorted -a $fn -b placentalMammals.phyloP46.bed -o mean | awk -F 't' '{printf (\"%st%4fn\", $1,$NF)}'\n",
    "done\n",
    "bedtools map -split -sorted -a /data/database/hg19/perGene/ENSG00000249993.1.bed -b placentalMammals.phyloP46.bed -o mean | awk -F 't' '{printf (\"%st%4fn\", $1,$NF)}'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/data5/galaxy/project/lncRNA_analysis/m6a_expression/brain.txt\n",
      "/data5/galaxy/project/lncRNA_analysis/m6a_expression/kidney.txt\n",
      "/data5/galaxy/project/lncRNA_analysis/m6a_expression/stomach.txt\n",
      "/data5/galaxy/project/lncRNA_analysis/m6a_expression/placenta.txt\n",
      "/data5/galaxy/project/lncRNA_analysis/m6a_expression/liver.txt\n",
      "/data5/galaxy/project/lncRNA_analysis/m6a_expression/lung.txt\n",
      "/data5/galaxy/project/lncRNA_analysis/m6a_expression/heart.txt\n",
      "/data5/galaxy/project/lncRNA_analysis/m6a_expression/muscle.txt\n"
     ]
    }
   ],
   "source": [
    "data_dir = \"/data5/galaxy/project/lncRNA_analysis/m6a_expression\"\n",
    "gene_bed = \"/data/database/hg19/genes_v28.bed\"\n",
    "df_bed = pd.read_table(gene_bed, sep=\"\\t\", header=None, names=[\"chr\", \"a\", \"b\", \"raw_name\", \"s\", \"stra\"])\n",
    "df_bed[\"name\"] = df_bed[\"raw_name\"].str.split(\".\").str[0]\n",
    "# print(df_bed.head())\n",
    "query_names = []\n",
    "for i_file in glob.glob(\"%s/*.txt\" % data_dir):\n",
    "    print(i_file)\n",
    "    t_names = read_file(i_file)\n",
    "#     print(t_names)\n",
    "    query_names = query_names + t_names\n",
    "df_result = df_bed[df_bed[\"name\"].isin(query_names)].dropna()\n",
    "#\n",
    "df_result[\"score\"] = df_result[\"b\"] - df_result[\"a\"]\n",
    "df_result = df_result[[\"chr\", \"a\", \"b\", \"raw_name\", \"score\", \"stra\"]]\n",
    "#\n",
    "df_result.to_csv(\"/data/database/ucsc_phylo/hg38/primate/query_gene.bed\", sep=\"\\t\", header=None, index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_file(in_file):\n",
    "    df = pd.read_table(in_file, sep=\"\\t\")\n",
    "    return df[\"name\"].tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "58288 45 58243\n"
     ]
    }
   ],
   "source": [
    "os.chdir(\"/data/database/ucsc_phylo/hg38/primate\")\n",
    "df = pd.read_table(\"Genes_ensembl_dot.bed\", sep=\"\\t\", header=None, names=[\"chr\", \"a\", \"b\", \"name\", \"s\", \"stra\"])\n",
    "df[\"score\"] = df[\"b\"] - df[\"a\"]\n",
    "df = df[[\"chr\", \"a\", \"b\", \"name\", \"score\", \"stra\"]].drop_duplicates()\n",
    "counter, dup_names = Counter(df[\"name\"].tolist()), []\n",
    "for term in counter:\n",
    "    if counter[term] >= 2:\n",
    "        dup_names.append(term)\n",
    "#         print(term, counter[term])\n",
    "# for name in dup_names:\n",
    "#     df_dup = df[df[\"name\"].isin([name])]\n",
    "#     print(df_dup)\n",
    "#     print(\"#####################\")\n",
    "uniq_names = [x for x in df[\"name\"].tolist() if x not in dup_names]\n",
    "df_result = df[(df[\"chr\"] != \"chrY\") | (df[\"name\"].isin(uniq_names))]\n",
    "print(len(df), len(dup_names), len(df_result))\n",
    "df_result.to_csv(\"Genes_ensembl_dot_format.bed\", sep=\"\\t\", header=None, index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "processing chromosomes\n"
     ]
    }
   ],
   "source": [
    "%%bash\n",
    "cd /data/database/ucsc_phylo/hg38/vertebrate\n",
    "bigWigAverageOverBed hg38.phyloP100way.bw ../primate/Genes_ensembl_dot_format.bed total_genes_result.tab"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_dir = \"/data5/galaxy/project/lncRNA_analysis/m6a_expression\"\n",
    "phastcons_file = \"/data/database/ucsc_phylo/hg38/vertebrate/total_genes_result.tab\"\n",
    "result_dir = data_dir\n",
    "df_score = pd.read_table(phastcons_file, sep=\"\\t\", header=None, names=[\"n\", \"size\", \"covered\", \"sum\", \"mean0\", \"mean\"])\n",
    "df_score[\"name\"] = df_score[\"n\"].str.split(\".\").str[0]\n",
    "del df_score[\"n\"]\n",
    "#\n",
    "for x in glob.glob(\"%s/*_phastCons.txt\" % data_dir):\n",
    "    os.remove(x)\n",
    "file_list = glob.glob(\"%s/*.txt\" % data_dir)\n",
    "# print(file_list)\n",
    "df_list = []\n",
    "for i_file in file_list:\n",
    "    tissue = os.path.basename(i_file).split(\".txt\")[0].lower()\n",
    "    df = pd.read_table(i_file, sep=\"\\t\")\n",
    "    df.columns = [\"name\", \"type\", \"FPKM\"]\n",
    "    df_merge = df_score.merge(df, on=\"name\", how=\"right\").dropna()\n",
    "#     df_merge = df_merge[[\"name\", \"type\", \"FPKM\", \"size\", \"covered\", \"sum\", \"mean0\", \"mean\"]]\n",
    "#     df_merge = df_merge.sort_values([\"type\"])\n",
    "    df_merge[\"tissue\"] = tissue\n",
    "    df_list.append(df_merge)\n",
    "df_total = pd.concat(df_list)\n",
    "df_total = df_total[[\"tissue\", \"name\", \"type\", \"FPKM\", \"size\", \"covered\", \"sum\", \"mean0\", \"mean\"]]\n",
    "df_total = df_total.sort_values([\"tissue\", \"type\"])\n",
    "result_file = \"%s/total-tissues_phastCons_vertebrate.txt\" % result_dir\n",
    "df_total.to_csv(result_file, sep=\"\\t\", index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
